{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Installation Setup",
   "id": "9f2f6784ca28e756"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "7e5dc24bf5240919"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns; sns.set()\n",
    "from pandas.tseries.offsets import *\n",
    "from dateutil.relativedelta import *\n",
    "import datetime as dt\n",
    "import os\n",
    "from linearmodels.asset_pricing import TradedFactorModel, LinearFactorModel\n",
    "from IPython.core.pylabtools import figsize\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from fredapi import Fred\n",
    "fred = Fred(api_key = 'b0363f9c9d853b92b27e06c4727bc2ea')\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "%matplotlib inline \n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20,10)"
   ],
   "id": "a0172cba3fbc65f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "from multiprocessing import Pool \n",
    "import random\n",
    "import json\n",
    "import sys\n",
    "import StockPortfolioEnv\n",
    "\n",
    "import pytz\n",
    "import itertools\n",
    "from datetime import datetime as dt\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ],
   "id": "5c6e0d9c07069b9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('mode.use_inf_as_na', True)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "idx = pd.IndexSlice\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "b8666a73b51a6fed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "f664534fe044103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_merged = pd.read_csv('data/merged.csv')\n",
    "df_merged"
   ],
   "id": "4280170d60326a36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Weight Initialization\n",
    "## Retail Weights (Rank-based method)"
   ],
   "id": "8036c9f9c776a15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute a set of weights for asset allocation\n",
    "df_merged['moribvol'] = df_merged.groupby(['date'])['moribvol'].rank(method='dense')\n",
    "df_merged['moribvol'] = df_merged.groupby('date')['moribvol'].apply(lambda x: x/x.sum())\n",
    "\n",
    "df_merged "
   ],
   "id": "b1c7edd36d709c59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mean-Variance Optimization Weights",
   "id": "cbb43711b239e3af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO: Compute and append mean variance weights to \"df_merged\" here, say column name as \"mean-var\"\n",
   "id": "b19aa85246312bff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Split",
   "id": "9bb06fc1c5e655be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "states = ['date', 'open', 'high', 'low', 'close', 'volume', 'tic', 'day', 'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'moribvol']\n",
    "\n",
    "train_data = data_split(df_merged[states], '2007-01-01', '2018-01-01')\n",
    "trade_data = data_split(df_merged[states], '2018-01-01', '2022-01-01')\n",
    "\n",
    "# boom bust?"
   ],
   "id": "7a9e8eedd9b6c0f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_data",
   "id": "210d34531d3e8ae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trade_data",
   "id": "ce604d2d8787c739"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Last, save both train and trade dfs to csv in data foler\n",
    "# TODO: add more features in \"state\" if needed\n",
    "train_data.to_csv('data/train_data.csv', index=True)  \n",
    "trade_data.to_csv('data/trade_data.csv', index=True) "
   ],
   "id": "af344f0aea08d7c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Benchmarks\n",
    "We compare the performance of different weighting methods on the train period\n",
    " - Mean Variance\n",
    " - Equally weighted (Buy and hold)\n",
    " - Market indexes (NASDAQ and XLK)\n",
    " - Individual stocks"
   ],
   "id": "e3fee2c83b1b9891"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Environment configuration\n",
    "> A gym-style portfolio allocation environment for agents to interact. It is handy to compare the performances."
   ],
   "id": "61a3ce3a891998fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train = train_data\n",
    "trade = trade_data\n",
    "\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "tech_indicator_list = ['macd', 'rsi_30', 'cci_30', 'dx_30']\n",
    "feature_dimension = len(tech_indicator_list)\n",
    "\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "print(f\"Feature Dimension: {feature_dimension}\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-1\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv.StockPortfolioEnv(df = train, **env_kwargs)\n",
    "e_trade_gym = StockPortfolioEnv.StockPortfolioEnv(df = trade, **env_kwargs)"
   ],
   "id": "dface87289dc0714"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Sampling",
   "id": "c77fd7ee8a255c1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "retail_train = StockPortfolioEnv.sample_from_env(i=0, env=e_train_gym, weights=train['moribvol'])",
   "id": "7ca6ae05f86ccc75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: to be changed to excecute like the above function\n",
    "\n",
    "# Mean variance\n",
    "mean_var_df = pd.read_csv('../data/mean_var_weight.csv')\n",
    "mean_var_df = pd.concat([mean_var_df.iloc[[0]], mean_var_df], ignore_index=True)\n",
    "mean_var_df = pd.concat([mean_var_df, mean_var_df.iloc[[len(mean_var_df)-1]]], ignore_index=True)\n",
    "mean_var_df.loc[0, 'date'] = '2007-01-03'\n",
    "mean_var_df.loc[len(mean_var_df)-1, 'date'] = '2017-12-29'\n",
    "mean_var_df = mean_var_df.drop(mean_var_df.columns[0], axis=1)\n",
    "\n",
    "mean_var_dataset = StockPortfolioEnv.sample_from_env(i=0, env=e_train_gym, weights=mean_var_df.values)\n",
    "mean_var_cum_ret = pd.DataFrame({'ret': 1000000 + np.insert(mean_var_dataset['rewards'].cumsum(), 0, 0, axis=0)})\n",
    "mean_var_cum_ret['ret'] /= 1000000"
   ],
   "id": "1e5b3436aafcace9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# XLK\n",
    "yf_xlk = YahooDownloader(start_date = start,\n",
    "                         end_date = end,\n",
    "                         ticker_list = [\"XLK\"]).fetch_data()\n",
    "\n",
    "yf_xlk = fe.preprocess_data(yf_xlk)\n",
    "yf_xlk = yf_xlk.copy()\n",
    "yf_xlk = yf_xlk.fillna(0)\n",
    "yf_xlk = yf_xlk.replace(np.inf,0)\n",
    "# yf_xlk['date'] = pd.to_datetime(yf_xlk['date'])\n",
    "yf_xlk = data_split(yf_xlk, '2007-01-01', '2018-01-01')  \n",
    "yf_xlk['ret'] = yf_xlk['open'] / yf_xlk['open'].iloc[0]"
   ],
   "id": "c95a328f9c525141"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# individual\n",
    "grouped = df_merged.groupby('tic')\n",
    "selected_cum_ret = grouped.apply(lambda x: x['open']/x['open'].iloc[0])\n",
    "selected_cum_ret = selected_cum_ret.reset_index()\n",
    "selected_cum_ret = selected_cum_ret.set_index('level_1')\n",
    "selected_cum_ret = selected_cum_ret.join(df_merged[['date']])\n",
    "selected_cum_ret = data_split(selected_cum_ret, '2007-01-01', '2018-01-01')"
   ],
   "id": "9a4ae1708f3b961b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Performance Comparison",
   "id": "151bc34bb0a94e40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Equal\n",
    "equal_cum_ret = pd.read_csv(\"./results/equal_cumulative_reward.csv\", names=['ret'])\n",
    "equal_cum_ret['date'] = selected_cum_ret['date'].unique()\n",
    "ax = equal_cum_ret.plot(ax=ax, kind='line', x='date', y='ret', label=\"Equal\")\n",
    "\n",
    "# Mean Variance\n",
    "mean_var_cum_ret['date'] = selected_cum_ret['date'].unique()\n",
    "ax = mean_var_cum_ret.plot(ax=ax, kind='line', x='date', y='ret', label=\"Mean Var\")\n",
    "\n",
    "# Retail\n",
    "retail_cum_ret = pd.read_csv(\"results/retail_cumulative_reward.csv\", names=['ret'])\n",
    "retail_cum_ret['date'] = selected_cum_ret['date'].unique()\n",
    "ax = retail_cum_ret.plot(ax=ax, kind='line', x='date', y='ret', label=\"Retail\")\n",
    "\n",
    "# XLK\n",
    "ax = yf_xlk.plot(ax=ax, kind='line', x='date', y='ret', label=\"XLK\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "ecb5e6243fb382c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 个股\n",
    "for key, grp in selected_cum_ret.groupby(['tic']):\n",
    "    ax = grp.plot(ax=ax, kind='line', x='date', y='open', label=key)\n",
    "    \n",
    "plt.show()"
   ],
   "id": "e3c94c84e888639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8fd9ee6560c6547f"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
